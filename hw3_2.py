# -*- coding: utf-8 -*-
"""HW3-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eW9NyR9ftFk_lnMKPr8r8293zwop2kms
"""

import numpy as np
import pandas as pd
import matplotlib    
import matplotlib.pyplot as plt
import math
from itertools import islice 
import random
from csv import reader
from math import sqrt
from math import exp
from math import pi
from sklearn.model_selection import train_test_split

def normal(power, mean, std, val):
    a = 1/(np.sqrt(2*np.pi)*std)
    diff = np.abs(np.power(val-mean, power))
    b = np.exp(-(diff)/(2*std*std))
    return a*b

def calculate_stdev( mean , data):
        n = len(data)-1
        sigma = 0
        for el in data:
            sigma += (el - mean)**2
        sigma = math.sqrt(sigma / n)
        return sigma

def calculate_mean(data):
        mean = sum(data) // len(data)
        return mean

def pdf(self, x):
        return (1.0 / (self.stdev * math.sqrt(2*math.pi))) * math.exp(-0.5*((x - self.mean) / self.stdev) ** 2)

def numbering(given_list):
  new_list = []
  for i in given_list:
    if i == "Iris-virginica":
      new_list.append(2)
    elif i == "Iris-versicolor":
      new_list.append(1)
    elif i == "Iris-setosa":
      new_list.append(0)
    else :
      print(error)
  return new_list

def load_csv(filename):
	dataset = list()
	with open(filename, 'r') as file:
		csv_reader = reader(file)
		for row in csv_reader:
			if not row:
				continue
			dataset.append(row)
	return dataset

def testing(test_set,model):
  label = []
  predicted = []
  j=0
  corrects = 0
  for i in test_set:
    label.append(i[4])
    i.remove(i[4])
    p = predict(model, i)
    predicted.append(p)
    print('Data=%s, Predicted=%s , Expected: %s' % (i,p, label[j] ))
    if p == label[j]:
      corrects +=1
    j+=1
 
  classes = int(max(label) - min(label)) + 1 #find number of classes
  counts = [[sum([(label[i] == true_class) and (predicted[i] == pred_class) 
                  for i in range(len(label))])
            for pred_class in range(1, classes + 1)] 
            for true_class in range(1, classes + 1)]
      
  print(" accuracy :%s "%(corrects/45))  # 45 is the length of 30% of dataset
  print("confiusion matrix : " )
  print(counts)

# Convert string column to float
def str_column_to_float(dataset, column):
	for row in dataset:
		row[column] = float(row[column].strip())

# Convert string column to integer
def str_column_to_int(dataset, column):
	class_values = [row[column] for row in dataset]
	unique = set(class_values)
	lookup = dict()
	for i, value in enumerate(unique):
		lookup[value] = i
		print('[%s] => %d' % (value, i))
	for row in dataset:
		row[column] = lookup[row[column]]
	return lookup

# Split the dataset by class values, returns a dictionary
def separate_by_class(dataset):
	separated = dict()
	for i in range(len(dataset)):
		vector = dataset[i]
		class_value = vector[-1]
		if (class_value not in separated):
			separated[class_value] = list()
		separated[class_value].append(vector)
	return separated

# Calculate the mean of a list of numbers
def mean(numbers):
	return sum(numbers)/float(len(numbers))

# Calculate the standard deviation of a list of numbers
def stdev(numbers):
	avg = mean(numbers)
	variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)
	return sqrt(variance)

# Calculate the mean, stdev and count for each column in a dataset
def summarize_dataset(dataset):
	summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]
	del(summaries[-1])
	return summaries

# Split dataset by class then calculate statistics for each row
def summarize_by_class(dataset):
	separated = separate_by_class(dataset)
	summaries = dict()
	for class_value, rows in separated.items():
		summaries[class_value] = summarize_dataset(rows)
	return summaries

# Calculate the Gaussian probability distribution function for x
def calculate_probability(x, mean, stdev):
	exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))
	return (1 / (sqrt(2 * pi) * stdev)) * exponent

# Calculate the probabilities of predicting each class for a given row
def calculate_class_probabilities(summaries, row):
	total_rows = sum([summaries[label][0][2] for label in summaries])
	probabilities = dict()
	for class_value, class_summaries in summaries.items():
		probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)
		for i in range(len(class_summaries)):
			mean, stdev, _ = class_summaries[i]
			probabilities[class_value] *= calculate_probability(row[i], mean, stdev)
	return probabilities

# Predict the class for a given row
def predict(summaries, row):
	probabilities = calculate_class_probabilities(summaries, row)
	best_label, best_prob = None, -1
	for class_value, probability in probabilities.items():
		if best_label is None or probability > best_prob:
			best_prob = probability
			best_label = class_value
	return best_label

# a . 70% train 30% test for the first time :
filename = '/content/iris .csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
dataset_train, dataset_test = train_test_split(dataset, test_size=0.30)
# fit model
model1 = summarize_by_class(dataset_train)
testing(dataset_test ,model1 )

# a . 70% train 30% test for the second time :
filename = '/content/iris .csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
dataset_train, dataset_test = train_test_split(dataset, test_size=0.30)
# fit model
model2 = summarize_by_class(dataset_train)
testing(dataset_test ,model2 )

"""so the average accuracy for part "a" ( 70% train 30% test ) is :
91.15 %

* part b ( 4 fold cross validation ) :
"""

filename = '/content/iris .csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)

# declares number of samples in each part for 4 fold cross validation
length_to_split = [37, 37, 37, 37] 
  
dataset = random.sample(dataset, len(dataset))

# Using islice 
Inputt = iter(dataset) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 
# folds[0] = test     rest = train
model2 = summarize_by_class(folds[1]+folds[2]+folds[3])
testing(folds[0] ,model2)

import numpy as np
import pandas as pd
from itertools import islice 
import random

filename = '/content/iris .csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
length_to_split = [37, 37, 37, 37] 
  
dataset = random.sample(dataset, len(dataset))

# Using islice 
Inputt = iter(dataset) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 
# folds[1] = test     rest = train
model2 = summarize_by_class(folds[0]+folds[2]+folds[3])
testing(folds[1] ,model2)

import numpy as np
import pandas as pd
from itertools import islice 
import random

filename = '/content/iris .csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
length_to_split = [37, 37, 37, 37] 
  
dataset = random.sample(dataset, len(dataset))

# Using islice 
Inputt = iter(dataset) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 
# folds[2] = test     rest = train
model2 = summarize_by_class(folds[0]+folds[1]+folds[3])
testing(folds[2] ,model2)

import numpy as np
import pandas as pd
from itertools import islice 
import random

filename = '/content/iris .csv'
dataset = load_csv(filename)
for i in range(len(dataset[0])-1):
	str_column_to_float(dataset, i)
# convert class column to integers
str_column_to_int(dataset, len(dataset[0])-1)
length_to_split = [37, 37, 37, 37] 
  
dataset = random.sample(dataset, len(dataset))

# Using islice 
Inputt = iter(dataset) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 
# folds[3] = test     rest = train
model2 = summarize_by_class(folds[1]+folds[2]+folds[0])
testing(folds[3] ,model2)

"""so the average accuracy for part "b" ( 4-fold cross validation) is : 79.4575 %

* Gaussian naive bayes :
"""

import numpy as np

class GaussianNBClassifier:
    def __init__(self):
        pass

    def separate_classes(self, X, y):
        separated_classes = {}
        for i in range(len(X)):
            feature_values = X[i]
            class_name = y[i]
            if tuple(class_name) not in tuple(separated_classes):
                separated_classes[tuple(class_name)] = ()
            list(separated_classes[tuple(class_name)]).append(feature_values)
        return separated_classes

    def summarize(self, X):
        for feature in zip(*X):
            yield {
                'stdev' : np.std(feature),
                'mean' : np.mean(feature)
            }
    def gauss_distribution_function(self, x, mean, stdev):
        exponent = np.exp(-((x-mean)**2 / (2*stdev**2)))
        return exponent / (np.sqrt(2*np.pi)*stdev)

    def fit(self, X, y):
        separated_classes = self.separate_classes(X, y)
        self.class_summary = {}
        for class_name, feature_values in separated_classes.items():
            self.class_summary[class_name] = {
                'prior_proba': len(feature_values)/len(X),
                'summary': [i for i in self.summarize(feature_values)],
            }     
        return self.class_summary


    def predict(self, X):
        MAPs = []
        for row in X:
            joint_proba = {}
            for class_name, features in self.class_summary.items():
                total_features = len(features['summary'])
                likelihood = 1
                for idx in range(total_features):
                    feature = row[idx]
                    mean = features['summary'][idx]['mean']
                    stdev = features['summary'][idx]['stdev']
                    normal_proba = self.gauss_distribution_function(feature, \
                    mean, stdev)
                    likelihood *= normal_proba
                prior_proba = features['prior_proba']
                joint_proba[class_name] = prior_proba * likelihood
            MAP = max(joint_proba, key=joint_proba.get)
            MAPs.append(MAP)
        return MAPs

    def accuracy(self, y_test, y_pred):
        true_true = 0
        for y_t, y_p in zip(y_test, y_pred):
            if y_t == y_p:
                true_true += 1
        return true_true / len(y_test)

"""*  Gaussian naive bayes on part " a " :"""

filename = '/content/iris .csv'
dataset = load_csv(filename)

X_train, X_test = train_test_split(dataset, test_size=0.30, random_state=42)

y_train = []
new_X_train = []
for x in X_train:
  y_train.append(x[4])
  x.remove(x[4])
  new_X_train.append(x)

y_test = []
new_X_test = []
for x in X_test:
  y_test.append(x[4])
  x.remove(x[4])
  new_X_test.append(x)

model = GaussianNBClassifier()
model.fit(new_X_train, y_train)
y_pred = model.predict(new_X_test)
word = ""
new_y_pred = []

for i in y_pred:
  for j in i:
    word += j 
  new_y_pred.append(word)
  word = ""

print ("GaussianNBClassifier accuracy: {0:.3f}".format(model.accuracy(y_test, new_y_pred)))


# numbering each class by 0 , 1 and 2 
new_y_pred = numbering(new_y_pred)

# the same thing for y_test 
new_y_test =  numbering(y_test)

classes = 3 # number of classes
counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) 
                for i in range(len(new_y_test))])
          for pred_class in range( classes )] 
          for true_class in range( classes )]
    
print("confiusion matrix : " )
print(counts)

"""* Gaussian naive bayes by 4-fold cross validation :"""

#from GaussianNBClassifier import GaussianNBClassifier
from pandas import DataFrame
from itertools import islice 

filename = '/content/iris .csv'
dataset = load_csv(filename)
length_to_split = [37, 37, 37, 37] 

#dataset = random.sample(dataset, len(dataset))
# Using islice to declare folds
Inputt = iter(random.sample(dataset, len(dataset))) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 

X_train = folds[1]+folds[2]+folds[0]
y_train = []
new_X_train = []
for x in X_train:
  y_train.append(x[4])
  x.remove(x[4])
  new_X_train.append(x)

X_test = folds[3]
y_test = []
new_X_test = []
for x in X_test:
  y_test.append(x[4])
  x.remove(x[4])
  new_X_test.append(x)

model = GaussianNBClassifier()
model.fit(new_X_train, y_train)
y_pred = model.predict(new_X_test)
word = ""
new_y_pred = []

for i in y_pred:
  for j in i:
    word += j 
  new_y_pred.append(word)
  word = ""

print ("GaussianNBClassifier accuracy: {0:.3f}".format(model.accuracy(y_test, new_y_pred)))

# numbering each class by 0 , 1 and 2 
new_y_pred = numbering(new_y_pred)

# the same thing for y_test 
new_y_test =  numbering(y_test)

classes = 3 # number of classes
counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) 
                for i in range(len(new_y_test))])
          for pred_class in range( classes )] 
          for true_class in range( classes )]
    
print("confiusion matrix : " )
print(counts)

#from GaussianNBClassifier import GaussianNBClassifier
from pandas import DataFrame
from itertools import islice 

filename = '/content/iris .csv'
dataset = load_csv(filename)
length_to_split = [37, 37, 37, 37] 

#dataset = random.sample(dataset, len(dataset))
# Using islice to declare folds
Inputt = iter(random.sample(dataset, len(dataset))) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 

X_train = folds[1]+folds[3]+folds[0]
y_train = []
new_X_train = []
for x in X_train:
  y_train.append(x[4])
  x.remove(x[4])
  new_X_train.append(x)

X_test = folds[2]
y_test = []
new_X_test = []
for x in X_test:
  y_test.append(x[4])
  x.remove(x[4])
  new_X_test.append(x)

model = GaussianNBClassifier()
model.fit(new_X_train, y_train)
y_pred = model.predict(new_X_test)
word = ""
new_y_pred = []

for i in y_pred:
  for j in i:
    word += j 
  new_y_pred.append(word)
  word = ""

print ("GaussianNBClassifier accuracy: {0:.3f}".format(model.accuracy(y_test, new_y_pred)))

# numbering each class by 0 , 1 and 2 
new_y_pred = numbering(new_y_pred)

# the same thing for y_test 
new_y_test =  numbering(y_test)

classes = 3 # number of classes
counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) 
                for i in range(len(y_test))])
          for pred_class in range( classes )] 
          for true_class in range( classes )]
    
print("confiusion matrix : " )
print(counts)

#from GaussianNBClassifier import GaussianNBClassifier
from pandas import DataFrame
from itertools import islice 

filename = '/content/iris .csv'
dataset = load_csv(filename)
length_to_split = [37, 37, 37, 37] 

#dataset = random.sample(dataset, len(dataset))
# Using islice  to declare folds
Inputt = iter(random.sample(dataset, len(dataset))) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 

X_train = folds[3]+folds[2]+folds[0]
y_train = []
new_X_train = []
for x in X_train:
  y_train.append(x[4])
  x.remove(x[4])
  new_X_train.append(x)

X_test = folds[1]
y_test = []
new_X_test = []
for x in X_test:
  y_test.append(x[4])
  x.remove(x[4])
  new_X_test.append(x)

model = GaussianNBClassifier()
model.fit(new_X_train, y_train)
y_pred = model.predict(new_X_test)
word = ""
new_y_pred = []

for i in y_pred:
  for j in i:
    word += j 
  new_y_pred.append(word)
  word = ""

print ("GaussianNBClassifier accuracy: {0:.3f}".format(model.accuracy(y_test, new_y_pred)))

# numbering each class by 0 , 1 and 2 
new_y_pred = numbering(new_y_pred)

# the same thing for y_test 
new_y_test =  numbering(y_test)

classes = 3 # number of classes
counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) 
                for i in range(len(y_test))])
          for pred_class in range( classes )] 
          for true_class in range( classes )]
    
print("confiusion matrix : " )
print(counts)

#from GaussianNBClassifier import GaussianNBClassifier
from pandas import DataFrame
from itertools import islice 

filename = '/content/iris .csv'
dataset = load_csv(filename)
length_to_split = [37, 37, 37, 37] 
#dataset = random.sample(dataset, len(dataset))
# Using islice to declare folds
Inputt = iter(random.sample(dataset, len(dataset))) 
folds = [list(islice(Inputt, elem)) 
          for elem in length_to_split] 

X_train = folds[1]+folds[2]+folds[3]
y_train = []
new_X_train = []
for x in X_train:
  y_train.append(x[4])
  x.remove(x[4])
  new_X_train.append(x)

X_test = folds[0]
y_test = []
new_X_test = []
for x in X_test:
  y_test.append(x[4])
  x.remove(x[4])
  new_X_test.append(x)

model = GaussianNBClassifier()
model.fit(new_X_train, y_train)
y_pred = model.predict(new_X_test)
word = ""
new_y_pred = []  

# fixing the template of data in y_pred form tuple to list
for i in y_pred:
  for j in i:
    word += j 
  new_y_pred.append(word)
  word = ""


print ("GaussianNBClassifier accuracy: {0:.3f}".format(model.accuracy(y_test, new_y_pred)))

# numbering each class by 0 , 1 and 2 
new_y_pred = numbering(new_y_pred)

# the same thing for y_test 
new_y_test =  numbering(y_test)

classes = 3 # number of classes
counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) 
                for i in range(len(y_test))])
          for pred_class in range( classes )] 
          for true_class in range( classes )]
    
print("confiusion matrix : " )
print(counts)

"""=> so the average for gaussian naive bayes is :
37.125 %

"""