{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ajKqVOJclH"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib    \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import math\r\n",
        "from itertools import islice \r\n",
        "import random\r\n",
        "from csv import reader\r\n",
        "from math import sqrt\r\n",
        "from math import exp\r\n",
        "from math import pi\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ8AsysbJoum"
      },
      "source": [
        "def normal(power, mean, std, val):\r\n",
        "    a = 1/(np.sqrt(2*np.pi)*std)\r\n",
        "    diff = np.abs(np.power(val-mean, power))\r\n",
        "    b = np.exp(-(diff)/(2*std*std))\r\n",
        "    return a*b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvQ6cpjhCzW4"
      },
      "source": [
        " def calculate_stdev( mean , data):\r\n",
        "        n = len(data)-1\r\n",
        "        sigma = 0\r\n",
        "        for el in data:\r\n",
        "            sigma += (el - mean)**2\r\n",
        "        sigma = math.sqrt(sigma / n)\r\n",
        "        return sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-cYHJKjCqnF"
      },
      "source": [
        " def calculate_mean(data):\r\n",
        "        mean = sum(data) // len(data)\r\n",
        "        return mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpwtWJAKDUYo"
      },
      "source": [
        " def pdf(self, x):\r\n",
        "        return (1.0 / (self.stdev * math.sqrt(2*math.pi))) * math.exp(-0.5*((x - self.mean) / self.stdev) ** 2)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yluKCz-waOAI"
      },
      "source": [
        "def numbering(given_list):\r\n",
        "  new_list = []\r\n",
        "  for i in given_list:\r\n",
        "    if i == \"Iris-virginica\":\r\n",
        "      new_list.append(2)\r\n",
        "    elif i == \"Iris-versicolor\":\r\n",
        "      new_list.append(1)\r\n",
        "    elif i == \"Iris-setosa\":\r\n",
        "      new_list.append(0)\r\n",
        "    else :\r\n",
        "      print(error)\r\n",
        "  return new_list\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcQw88GHoMDK"
      },
      "source": [
        "\r\n",
        "def load_csv(filename):\r\n",
        "\tdataset = list()\r\n",
        "\twith open(filename, 'r') as file:\r\n",
        "\t\tcsv_reader = reader(file)\r\n",
        "\t\tfor row in csv_reader:\r\n",
        "\t\t\tif not row:\r\n",
        "\t\t\t\tcontinue\r\n",
        "\t\t\tdataset.append(row)\r\n",
        "\treturn dataset\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1oaeCZNLxZV"
      },
      "source": [
        "def testing(test_set,model):\r\n",
        "  label = []\r\n",
        "  predicted = []\r\n",
        "  j=0\r\n",
        "  corrects = 0\r\n",
        "  for i in test_set:\r\n",
        "    label.append(i[4])\r\n",
        "    i.remove(i[4])\r\n",
        "    p = predict(model, i)\r\n",
        "    predicted.append(p)\r\n",
        "    print('Data=%s, Predicted=%s , Expected: %s' % (i,p, label[j] ))\r\n",
        "    if p == label[j]:\r\n",
        "      corrects +=1\r\n",
        "    j+=1\r\n",
        " \r\n",
        "  classes = int(max(label) - min(label)) + 1 #find number of classes\r\n",
        "  counts = [[sum([(label[i] == true_class) and (predicted[i] == pred_class) \r\n",
        "                  for i in range(len(label))])\r\n",
        "            for pred_class in range(1, classes + 1)] \r\n",
        "            for true_class in range(1, classes + 1)]\r\n",
        "      \r\n",
        "  print(\" accuracy :%s \"%(corrects/45))  # 45 is the length of 30% of dataset\r\n",
        "  print(\"confiusion matrix : \" )\r\n",
        "  print(counts)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPnQ23B_kgxw"
      },
      "source": [
        "\r\n",
        "# Convert string column to float\r\n",
        "def str_column_to_float(dataset, column):\r\n",
        "\tfor row in dataset:\r\n",
        "\t\trow[column] = float(row[column].strip())\r\n",
        "\r\n",
        "# Convert string column to integer\r\n",
        "def str_column_to_int(dataset, column):\r\n",
        "\tclass_values = [row[column] for row in dataset]\r\n",
        "\tunique = set(class_values)\r\n",
        "\tlookup = dict()\r\n",
        "\tfor i, value in enumerate(unique):\r\n",
        "\t\tlookup[value] = i\r\n",
        "\t\tprint('[%s] => %d' % (value, i))\r\n",
        "\tfor row in dataset:\r\n",
        "\t\trow[column] = lookup[row[column]]\r\n",
        "\treturn lookup\r\n",
        "\r\n",
        "# Split the dataset by class values, returns a dictionary\r\n",
        "def separate_by_class(dataset):\r\n",
        "\tseparated = dict()\r\n",
        "\tfor i in range(len(dataset)):\r\n",
        "\t\tvector = dataset[i]\r\n",
        "\t\tclass_value = vector[-1]\r\n",
        "\t\tif (class_value not in separated):\r\n",
        "\t\t\tseparated[class_value] = list()\r\n",
        "\t\tseparated[class_value].append(vector)\r\n",
        "\treturn separated\r\n",
        "\r\n",
        "# Calculate the mean of a list of numbers\r\n",
        "def mean(numbers):\r\n",
        "\treturn sum(numbers)/float(len(numbers))\r\n",
        "\r\n",
        "# Calculate the standard deviation of a list of numbers\r\n",
        "def stdev(numbers):\r\n",
        "\tavg = mean(numbers)\r\n",
        "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\r\n",
        "\treturn sqrt(variance)\r\n",
        "\r\n",
        "# Calculate the mean, stdev and count for each column in a dataset\r\n",
        "def summarize_dataset(dataset):\r\n",
        "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\r\n",
        "\tdel(summaries[-1])\r\n",
        "\treturn summaries\r\n",
        "\r\n",
        "# Split dataset by class then calculate statistics for each row\r\n",
        "def summarize_by_class(dataset):\r\n",
        "\tseparated = separate_by_class(dataset)\r\n",
        "\tsummaries = dict()\r\n",
        "\tfor class_value, rows in separated.items():\r\n",
        "\t\tsummaries[class_value] = summarize_dataset(rows)\r\n",
        "\treturn summaries\r\n",
        "\r\n",
        "# Calculate the Gaussian probability distribution function for x\r\n",
        "def calculate_probability(x, mean, stdev):\r\n",
        "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\r\n",
        "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent\r\n",
        "\r\n",
        "# Calculate the probabilities of predicting each class for a given row\r\n",
        "def calculate_class_probabilities(summaries, row):\r\n",
        "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\r\n",
        "\tprobabilities = dict()\r\n",
        "\tfor class_value, class_summaries in summaries.items():\r\n",
        "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\r\n",
        "\t\tfor i in range(len(class_summaries)):\r\n",
        "\t\t\tmean, stdev, _ = class_summaries[i]\r\n",
        "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\r\n",
        "\treturn probabilities\r\n",
        "\r\n",
        "# Predict the class for a given row\r\n",
        "def predict(summaries, row):\r\n",
        "\tprobabilities = calculate_class_probabilities(summaries, row)\r\n",
        "\tbest_label, best_prob = None, -1\r\n",
        "\tfor class_value, probability in probabilities.items():\r\n",
        "\t\tif best_label is None or probability > best_prob:\r\n",
        "\t\t\tbest_prob = probability\r\n",
        "\t\t\tbest_label = class_value\r\n",
        "\treturn best_label\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a5BR9lLDb06",
        "outputId": "894c842a-2a19-4433-b4cf-70ec6d918557"
      },
      "source": [
        "# a . 70% train 30% test for the first time :\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])-1):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# convert class column to integers\r\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
        "dataset_train, dataset_test = train_test_split(dataset, test_size=0.30)\r\n",
        "# fit model\r\n",
        "model1 = summarize_by_class(dataset_train)\r\n",
        "testing(dataset_test ,model1 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iris-versicolor] => 0\n",
            "[Iris-virginica] => 1\n",
            "[Iris-setosa] => 2\n",
            "Data=[5.2, 3.4, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.9, 3.1, 4.9, 1.5], Predicted=1 , Expected: 0\n",
            "Data=[6.7, 3.3, 5.7, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[6.9, 3.1, 5.4, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[5.7, 2.5, 5.0, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[7.2, 3.0, 5.8, 1.6], Predicted=1 , Expected: 1\n",
            "Data=[6.3, 3.3, 4.7, 1.6], Predicted=1 , Expected: 0\n",
            "Data=[5.1, 3.5, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[5.8, 2.8, 5.1, 2.4], Predicted=1 , Expected: 1\n",
            "Data=[6.4, 2.8, 5.6, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[4.9, 3.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[5.7, 2.6, 3.5, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[4.8, 3.4, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.0, 3.4, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.8, 4.0, 1.2, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[4.5, 2.3, 1.3, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[4.8, 3.0, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[6.0, 3.4, 4.5, 1.6], Predicted=0 , Expected: 0\n",
            "Data=[5.1, 3.3, 1.7, 0.5], Predicted=2 , Expected: 2\n",
            "Data=[6.9, 3.1, 5.1, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[5.1, 2.5, 3.0, 1.1], Predicted=0 , Expected: 0\n",
            "Data=[6.0, 2.9, 4.5, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.0, 3.0, 4.8, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[6.8, 3.0, 5.5, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[6.3, 3.4, 5.6, 2.4], Predicted=1 , Expected: 1\n",
            "Data=[5.1, 3.8, 1.9, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[5.0, 3.2, 1.2, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[4.7, 3.2, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.3, 2.5, 4.9, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.1, 2.9, 4.7, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.9, 3.2, 4.8, 1.8], Predicted=1 , Expected: 0\n",
            "Data=[5.0, 3.5, 1.3, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[6.7, 3.3, 5.7, 2.5], Predicted=1 , Expected: 1\n",
            "Data=[5.1, 3.4, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.5, 2.5, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.8, 3.2, 5.9, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[5.9, 3.0, 4.2, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 2.9, 4.2, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.8, 2.7, 3.9, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[5.6, 2.7, 4.2, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.0, 2.7, 5.1, 1.6], Predicted=1 , Expected: 0\n",
            "Data=[6.3, 2.8, 5.1, 1.5], Predicted=0 , Expected: 1\n",
            "Data=[6.2, 2.8, 4.8, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[6.6, 3.0, 4.4, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[6.7, 3.1, 4.4, 1.4], Predicted=0 , Expected: 0\n",
            " accuracy :0.8888888888888888 \n",
            "confiusion matrix : \n",
            "[[13, 0, 0], [0, 14, 0], [0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLRJJK2AvJbr",
        "outputId": "c88d121a-4899-4ad8-cbfb-47f4947a0e22"
      },
      "source": [
        " # a . 70% train 30% test for the second time :\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])-1):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# convert class column to integers\r\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
        "dataset_train, dataset_test = train_test_split(dataset, test_size=0.30)\r\n",
        "# fit model\r\n",
        "model2 = summarize_by_class(dataset_train)\r\n",
        "testing(dataset_test ,model2 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iris-versicolor] => 0\n",
            "[Iris-virginica] => 1\n",
            "[Iris-setosa] => 2\n",
            "Data=[5.1, 2.5, 3.0, 1.1], Predicted=0 , Expected: 0\n",
            "Data=[5.9, 3.2, 4.8, 1.8], Predicted=1 , Expected: 0\n",
            "Data=[4.7, 3.2, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.2, 3.4, 5.4, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[7.3, 2.9, 6.3, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[4.4, 2.9, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.1, 2.8, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.7, 3.3, 5.7, 2.5], Predicted=1 , Expected: 1\n",
            "Data=[6.4, 2.7, 5.3, 1.9], Predicted=1 , Expected: 1\n",
            "Data=[5.5, 2.5, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.3, 2.9, 5.6, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[6.6, 3.0, 4.4, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.2, 2.7, 3.9, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[6.8, 3.2, 5.9, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[5.9, 3.0, 4.2, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[5.8, 2.6, 4.0, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 2.8, 4.5, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.4, 3.9, 1.7, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[5.1, 3.5, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[5.0, 3.4, 1.6, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[6.4, 3.2, 5.3, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[4.8, 3.4, 1.9, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.4, 3.9, 1.3, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[5.7, 2.5, 5.0, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.0, 3.2, 1.2, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.6, 3.0, 4.5, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.9, 3.1, 4.9, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[4.9, 3.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[5.8, 2.7, 4.1, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.1, 3.3, 1.7, 0.5], Predicted=2 , Expected: 2\n",
            "Data=[5.0, 3.5, 1.6, 0.6], Predicted=2 , Expected: 2\n",
            "Data=[4.6, 3.4, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[5.7, 2.9, 4.2, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.2, 2.8, 4.8, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[5.1, 3.7, 1.5, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[7.7, 3.0, 6.1, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[6.0, 2.2, 5.0, 1.5], Predicted=0 , Expected: 1\n",
            "Data=[6.2, 2.9, 4.3, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.5, 2.4, 3.8, 1.1], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 2.6, 3.5, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[6.1, 2.6, 5.6, 1.4], Predicted=0 , Expected: 1\n",
            "Data=[6.5, 2.8, 4.6, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[5.2, 4.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[5.2, 3.4, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.5, 2.6, 4.4, 1.2], Predicted=0 , Expected: 0\n",
            " accuracy :0.9333333333333333 \n",
            "confiusion matrix : \n",
            "[[10, 0, 0], [0, 15, 0], [0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2cElTtMhWvO"
      },
      "source": [
        "so the average accuracy for part \"a\" ( 70% train 30% test ) is :\r\n",
        "91.15 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM9VdDUku10r"
      },
      "source": [
        "* part b ( 4 fold cross validation ) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmiwCnMoi1Z2",
        "outputId": "53dbdc3b-fe41-4f3c-e852-01fc903d045f"
      },
      "source": [
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])-1):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# convert class column to integers\r\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
        "\r\n",
        "# declares number of samples in each part for 4 fold cross validation\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "  \r\n",
        "dataset = random.sample(dataset, len(dataset))\r\n",
        "\r\n",
        "# Using islice \r\n",
        "Inputt = iter(dataset) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "# folds[0] = test     rest = train\r\n",
        "model2 = summarize_by_class(folds[1]+folds[2]+folds[3])\r\n",
        "testing(folds[0] ,model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iris-versicolor] => 0\n",
            "[Iris-virginica] => 1\n",
            "[Iris-setosa] => 2\n",
            "Data=[5.8, 2.7, 4.1, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.4, 3.9, 1.3, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[4.4, 3.0, 1.3, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.5, 3.2, 5.1, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[4.8, 3.4, 1.9, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.6, 2.8, 4.9, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.3, 3.7, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.7, 3.3, 5.7, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[6.5, 3.0, 5.2, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.5, 2.5, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[4.9, 2.4, 3.3, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.5, 2.4, 3.7, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[6.0, 3.0, 4.8, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[5.8, 2.7, 3.9, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[6.7, 3.0, 5.2, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[6.7, 3.1, 4.7, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.1, 2.6, 5.6, 1.4], Predicted=0 , Expected: 1\n",
            "Data=[6.3, 2.5, 4.9, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.0, 2.2, 4.0, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[7.1, 3.0, 5.9, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[5.4, 3.9, 1.7, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[6.1, 2.9, 4.7, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[7.0, 3.2, 4.7, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.0, 3.6, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.4, 2.8, 5.6, 2.2], Predicted=1 , Expected: 1\n",
            "Data=[6.3, 2.5, 5.0, 1.9], Predicted=1 , Expected: 1\n",
            "Data=[6.2, 2.8, 4.8, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[5.2, 3.4, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.7, 4.4, 1.5, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[5.7, 2.8, 4.5, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.0, 3.4, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.7, 3.1, 5.6, 2.4], Predicted=1 , Expected: 1\n",
            "Data=[5.7, 2.9, 4.2, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.0, 3.2, 1.2, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.0, 2.3, 3.3, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 3.0, 4.2, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[4.8, 3.0, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            " accuracy :0.8 \n",
            "confiusion matrix : \n",
            "[[11, 0, 0], [0, 11, 0], [0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mpn-zPjlaJV",
        "outputId": "035533da-c49e-47b7-d9e6-8b00384f3811"
      },
      "source": [
        " import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from itertools import islice \r\n",
        "import random\r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])-1):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# convert class column to integers\r\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "  \r\n",
        "dataset = random.sample(dataset, len(dataset))\r\n",
        "\r\n",
        "# Using islice \r\n",
        "Inputt = iter(dataset) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "# folds[1] = test     rest = train\r\n",
        "model2 = summarize_by_class(folds[0]+folds[2]+folds[3])\r\n",
        "testing(folds[1] ,model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iris-versicolor] => 0\n",
            "[Iris-virginica] => 1\n",
            "[Iris-setosa] => 2\n",
            "Data=[6.5, 3.0, 5.5, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[6.9, 3.1, 5.4, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[5.7, 3.0, 4.2, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[5.6, 2.5, 3.9, 1.1], Predicted=0 , Expected: 0\n",
            "Data=[4.8, 3.0, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[5.9, 3.0, 5.1, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[5.5, 4.2, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.1, 2.8, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.1, 3.8, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.7, 2.9, 4.2, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.1, 3.0, 4.6, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[7.4, 2.8, 6.1, 1.9], Predicted=1 , Expected: 1\n",
            "Data=[6.1, 2.8, 4.7, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[6.9, 3.1, 4.9, 1.5], Predicted=1 , Expected: 0\n",
            "Data=[5.0, 2.3, 3.3, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.2, 2.7, 3.9, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.4, 3.4, 1.7, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[7.2, 3.6, 6.1, 2.5], Predicted=1 , Expected: 1\n",
            "Data=[6.5, 3.2, 5.1, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.7, 2.8, 4.1, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[6.7, 3.1, 4.4, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[4.9, 3.0, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[4.9, 3.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[4.8, 3.1, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.2, 4.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[6.1, 2.9, 4.7, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.4, 3.9, 1.7, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[4.9, 2.5, 4.5, 1.7], Predicted=0 , Expected: 1\n",
            "Data=[5.1, 2.5, 3.0, 1.1], Predicted=0 , Expected: 0\n",
            "Data=[4.4, 2.9, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[4.8, 3.4, 1.9, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.3, 2.3, 4.4, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[4.6, 3.1, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.4, 3.0, 4.5, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[4.6, 3.2, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.4, 2.8, 5.6, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[5.8, 2.6, 4.0, 1.2], Predicted=0 , Expected: 0\n",
            " accuracy :0.7777777777777778 \n",
            "confiusion matrix : \n",
            "[[7, 0, 0], [0, 13, 0], [0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlxSeUvwnzqd",
        "outputId": "b66eabee-8bfa-47dc-e55a-be5fa51dd747"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from itertools import islice \r\n",
        "import random\r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])-1):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# convert class column to integers\r\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "  \r\n",
        "dataset = random.sample(dataset, len(dataset))\r\n",
        "\r\n",
        "# Using islice \r\n",
        "Inputt = iter(dataset) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "# folds[2] = test     rest = train\r\n",
        "model2 = summarize_by_class(folds[0]+folds[1]+folds[3])\r\n",
        "testing(folds[2] ,model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iris-versicolor] => 0\n",
            "[Iris-virginica] => 1\n",
            "[Iris-setosa] => 2\n",
            "Data=[5.5, 2.5, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[7.2, 3.0, 5.8, 1.6], Predicted=1 , Expected: 1\n",
            "Data=[6.9, 3.1, 4.9, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.3, 2.8, 5.1, 1.5], Predicted=0 , Expected: 1\n",
            "Data=[5.1, 3.8, 1.5, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[4.7, 3.2, 1.3, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[4.4, 2.9, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[4.9, 2.4, 3.3, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[6.3, 2.9, 5.6, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[5.0, 3.4, 1.6, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[6.1, 2.6, 5.6, 1.4], Predicted=0 , Expected: 1\n",
            "Data=[5.6, 2.7, 4.2, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 3.8, 1.7, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[6.3, 2.5, 5.0, 1.9], Predicted=1 , Expected: 1\n",
            "Data=[5.2, 2.7, 3.9, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.6, 2.8, 4.9, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.0, 3.0, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.2, 2.8, 4.8, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[4.8, 3.0, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[6.3, 3.4, 5.6, 2.4], Predicted=1 , Expected: 1\n",
            "Data=[6.3, 2.7, 4.9, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[6.2, 2.2, 4.5, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[7.9, 3.8, 6.4, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[6.5, 3.2, 5.1, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.3, 3.7, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[7.1, 3.0, 5.9, 2.1], Predicted=1 , Expected: 1\n",
            "Data=[4.6, 3.6, 1.0, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.7, 3.3, 5.7, 2.5], Predicted=1 , Expected: 1\n",
            "Data=[7.7, 2.8, 6.7, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.8, 2.7, 4.1, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.0, 2.0, 3.5, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[4.3, 3.0, 1.1, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[6.6, 3.0, 4.4, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.5, 2.4, 3.8, 1.1], Predicted=0 , Expected: 0\n",
            "Data=[4.7, 3.2, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[7.7, 2.6, 6.9, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[6.7, 3.3, 5.7, 2.1], Predicted=1 , Expected: 1\n",
            " accuracy :0.7777777777777778 \n",
            "confiusion matrix : \n",
            "[[14, 0, 0], [0, 11, 0], [0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhLNlAOTiylt",
        "outputId": "138e95e6-1957-4f7b-c123-93f77e415ac7"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from itertools import islice \r\n",
        "import random\r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "for i in range(len(dataset[0])-1):\r\n",
        "\tstr_column_to_float(dataset, i)\r\n",
        "# convert class column to integers\r\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "  \r\n",
        "dataset = random.sample(dataset, len(dataset))\r\n",
        "\r\n",
        "# Using islice \r\n",
        "Inputt = iter(dataset) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "# folds[3] = test     rest = train\r\n",
        "model2 = summarize_by_class(folds[1]+folds[2]+folds[0])\r\n",
        "testing(folds[3] ,model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Iris-versicolor] => 0\n",
            "[Iris-virginica] => 1\n",
            "[Iris-setosa] => 2\n",
            "Data=[5.1, 3.5, 1.4, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[4.9, 3.0, 1.4, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.8, 2.7, 3.9, 1.2], Predicted=0 , Expected: 0\n",
            "Data=[7.2, 3.0, 5.8, 1.6], Predicted=1 , Expected: 1\n",
            "Data=[6.4, 3.2, 4.5, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.1, 2.8, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.9, 3.0, 4.2, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.7, 3.3, 5.7, 2.5], Predicted=1 , Expected: 1\n",
            "Data=[4.8, 3.4, 1.9, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.3, 3.3, 4.7, 1.6], Predicted=0 , Expected: 0\n",
            "Data=[6.5, 3.2, 5.1, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[6.7, 3.1, 4.4, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 2.5, 5.0, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[6.7, 3.1, 4.7, 1.5], Predicted=0 , Expected: 0\n",
            "Data=[6.9, 3.1, 5.1, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[7.2, 3.6, 6.1, 2.5], Predicted=1 , Expected: 1\n",
            "Data=[4.5, 2.3, 1.3, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[6.4, 3.1, 5.5, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[5.4, 3.4, 1.5, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[4.8, 3.0, 1.4, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[6.6, 2.9, 4.6, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.0, 3.2, 1.2, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[5.0, 3.0, 1.6, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.8, 2.8, 4.8, 1.4], Predicted=0 , Expected: 0\n",
            "Data=[6.2, 3.4, 5.4, 2.3], Predicted=1 , Expected: 1\n",
            "Data=[6.5, 3.0, 5.5, 1.8], Predicted=1 , Expected: 1\n",
            "Data=[4.9, 3.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[5.5, 2.5, 4.0, 1.3], Predicted=0 , Expected: 0\n",
            "Data=[5.7, 2.6, 3.5, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.2, 4.1, 1.5, 0.1], Predicted=2 , Expected: 2\n",
            "Data=[4.9, 2.4, 3.3, 1.0], Predicted=0 , Expected: 0\n",
            "Data=[5.4, 3.9, 1.7, 0.4], Predicted=2 , Expected: 2\n",
            "Data=[5.1, 3.8, 1.5, 0.3], Predicted=2 , Expected: 2\n",
            "Data=[7.4, 2.8, 6.1, 1.9], Predicted=1 , Expected: 1\n",
            "Data=[5.2, 3.5, 1.5, 0.2], Predicted=2 , Expected: 2\n",
            "Data=[6.5, 3.0, 5.2, 2.0], Predicted=1 , Expected: 1\n",
            "Data=[5.7, 3.8, 1.7, 0.3], Predicted=2 , Expected: 2\n",
            " accuracy :0.8222222222222222 \n",
            "confiusion matrix : \n",
            "[[11, 0, 0], [0, 14, 0], [0, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVqJIkFGijuG"
      },
      "source": [
        "so the average accuracy for part \"b\" ( 4-fold cross validation) is : 79.4575 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5JME2ARlOOT"
      },
      "source": [
        "* Gaussian naive bayes :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvQorUjs_y4"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "class GaussianNBClassifier:\r\n",
        "    def __init__(self):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def separate_classes(self, X, y):\r\n",
        "        separated_classes = {}\r\n",
        "        for i in range(len(X)):\r\n",
        "            feature_values = X[i]\r\n",
        "            class_name = y[i]\r\n",
        "            if tuple(class_name) not in tuple(separated_classes):\r\n",
        "                separated_classes[tuple(class_name)] = ()\r\n",
        "            list(separated_classes[tuple(class_name)]).append(feature_values)\r\n",
        "        return separated_classes\r\n",
        "\r\n",
        "    def summarize(self, X):\r\n",
        "        for feature in zip(*X):\r\n",
        "            yield {\r\n",
        "                'stdev' : np.std(feature),\r\n",
        "                'mean' : np.mean(feature)\r\n",
        "            }\r\n",
        "    def gauss_distribution_function(self, x, mean, stdev):\r\n",
        "        exponent = np.exp(-((x-mean)**2 / (2*stdev**2)))\r\n",
        "        return exponent / (np.sqrt(2*np.pi)*stdev)\r\n",
        "\r\n",
        "    def fit(self, X, y):\r\n",
        "        separated_classes = self.separate_classes(X, y)\r\n",
        "        self.class_summary = {}\r\n",
        "        for class_name, feature_values in separated_classes.items():\r\n",
        "            self.class_summary[class_name] = {\r\n",
        "                'prior_proba': len(feature_values)/len(X),\r\n",
        "                'summary': [i for i in self.summarize(feature_values)],\r\n",
        "            }     \r\n",
        "        return self.class_summary\r\n",
        "\r\n",
        "\r\n",
        "    def predict(self, X):\r\n",
        "        MAPs = []\r\n",
        "        for row in X:\r\n",
        "            joint_proba = {}\r\n",
        "            for class_name, features in self.class_summary.items():\r\n",
        "                total_features = len(features['summary'])\r\n",
        "                likelihood = 1\r\n",
        "                for idx in range(total_features):\r\n",
        "                    feature = row[idx]\r\n",
        "                    mean = features['summary'][idx]['mean']\r\n",
        "                    stdev = features['summary'][idx]['stdev']\r\n",
        "                    normal_proba = self.gauss_distribution_function(feature, \\\r\n",
        "                    mean, stdev)\r\n",
        "                    likelihood *= normal_proba\r\n",
        "                prior_proba = features['prior_proba']\r\n",
        "                joint_proba[class_name] = prior_proba * likelihood\r\n",
        "            MAP = max(joint_proba, key=joint_proba.get)\r\n",
        "            MAPs.append(MAP)\r\n",
        "        return MAPs\r\n",
        "\r\n",
        "    def accuracy(self, y_test, y_pred):\r\n",
        "        true_true = 0\r\n",
        "        for y_t, y_p in zip(y_test, y_pred):\r\n",
        "            if y_t == y_p:\r\n",
        "                true_true += 1\r\n",
        "        return true_true / len(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgWIL4R7kHFg"
      },
      "source": [
        "*  Gaussian naive bayes on part \" a \" :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFjmJzEnkGjE",
        "outputId": "4792b001-b873-42a7-9d98-b7abb7b4dc63"
      },
      "source": [
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "\r\n",
        "X_train, X_test = train_test_split(dataset, test_size=0.30, random_state=42)\r\n",
        "\r\n",
        "y_train = []\r\n",
        "new_X_train = []\r\n",
        "for x in X_train:\r\n",
        "  y_train.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_train.append(x)\r\n",
        "\r\n",
        "y_test = []\r\n",
        "new_X_test = []\r\n",
        "for x in X_test:\r\n",
        "  y_test.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_test.append(x)\r\n",
        "\r\n",
        "model = GaussianNBClassifier()\r\n",
        "model.fit(new_X_train, y_train)\r\n",
        "y_pred = model.predict(new_X_test)\r\n",
        "word = \"\"\r\n",
        "new_y_pred = []\r\n",
        "\r\n",
        "for i in y_pred:\r\n",
        "  for j in i:\r\n",
        "    word += j \r\n",
        "  new_y_pred.append(word)\r\n",
        "  word = \"\"\r\n",
        "\r\n",
        "print (\"GaussianNBClassifier accuracy: {0:.3f}\".format(model.accuracy(y_test, new_y_pred)))\r\n",
        "\r\n",
        "\r\n",
        "# numbering each class by 0 , 1 and 2 \r\n",
        "new_y_pred = numbering(new_y_pred)\r\n",
        "\r\n",
        "# the same thing for y_test \r\n",
        "new_y_test =  numbering(y_test)\r\n",
        "\r\n",
        "classes = 3 # number of classes\r\n",
        "counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) \r\n",
        "                for i in range(len(new_y_test))])\r\n",
        "          for pred_class in range( classes )] \r\n",
        "          for true_class in range( classes )]\r\n",
        "    \r\n",
        "print(\"confiusion matrix : \" )\r\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNBClassifier accuracy: 0.289\n",
            "confiusion matrix : \n",
            "[[0, 19, 0], [0, 13, 0], [0, 13, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANy5UZHyjxo8"
      },
      "source": [
        "* Gaussian naive bayes by 4-fold cross validation :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR4qpVgytlY4",
        "outputId": "30dcf108-6e2e-470a-d71a-3994fdfc54d2"
      },
      "source": [
        "#from GaussianNBClassifier import GaussianNBClassifier\r\n",
        "from pandas import DataFrame\r\n",
        "from itertools import islice \r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "\r\n",
        "#dataset = random.sample(dataset, len(dataset))\r\n",
        "# Using islice to declare folds\r\n",
        "Inputt = iter(random.sample(dataset, len(dataset))) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "\r\n",
        "X_train = folds[1]+folds[2]+folds[0]\r\n",
        "y_train = []\r\n",
        "new_X_train = []\r\n",
        "for x in X_train:\r\n",
        "  y_train.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_train.append(x)\r\n",
        "\r\n",
        "X_test = folds[3]\r\n",
        "y_test = []\r\n",
        "new_X_test = []\r\n",
        "for x in X_test:\r\n",
        "  y_test.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_test.append(x)\r\n",
        "\r\n",
        "model = GaussianNBClassifier()\r\n",
        "model.fit(new_X_train, y_train)\r\n",
        "y_pred = model.predict(new_X_test)\r\n",
        "word = \"\"\r\n",
        "new_y_pred = []\r\n",
        "\r\n",
        "for i in y_pred:\r\n",
        "  for j in i:\r\n",
        "    word += j \r\n",
        "  new_y_pred.append(word)\r\n",
        "  word = \"\"\r\n",
        "\r\n",
        "print (\"GaussianNBClassifier accuracy: {0:.3f}\".format(model.accuracy(y_test, new_y_pred)))\r\n",
        "\r\n",
        "# numbering each class by 0 , 1 and 2 \r\n",
        "new_y_pred = numbering(new_y_pred)\r\n",
        "\r\n",
        "# the same thing for y_test \r\n",
        "new_y_test =  numbering(y_test)\r\n",
        "\r\n",
        "classes = 3 # number of classes\r\n",
        "counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) \r\n",
        "                for i in range(len(new_y_test))])\r\n",
        "          for pred_class in range( classes )] \r\n",
        "          for true_class in range( classes )]\r\n",
        "    \r\n",
        "print(\"confiusion matrix : \" )\r\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNBClassifier accuracy: 0.378\n",
            "confiusion matrix : \n",
            "[[14, 0, 0], [11, 0, 0], [12, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8aXKvLMFUUE",
        "outputId": "a616abdc-d942-4183-8d9a-cc5ad48fb48a"
      },
      "source": [
        "#from GaussianNBClassifier import GaussianNBClassifier\r\n",
        "from pandas import DataFrame\r\n",
        "from itertools import islice \r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "\r\n",
        "#dataset = random.sample(dataset, len(dataset))\r\n",
        "# Using islice to declare folds\r\n",
        "Inputt = iter(random.sample(dataset, len(dataset))) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "\r\n",
        "X_train = folds[1]+folds[3]+folds[0]\r\n",
        "y_train = []\r\n",
        "new_X_train = []\r\n",
        "for x in X_train:\r\n",
        "  y_train.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_train.append(x)\r\n",
        "\r\n",
        "X_test = folds[2]\r\n",
        "y_test = []\r\n",
        "new_X_test = []\r\n",
        "for x in X_test:\r\n",
        "  y_test.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_test.append(x)\r\n",
        "\r\n",
        "model = GaussianNBClassifier()\r\n",
        "model.fit(new_X_train, y_train)\r\n",
        "y_pred = model.predict(new_X_test)\r\n",
        "word = \"\"\r\n",
        "new_y_pred = []\r\n",
        "\r\n",
        "for i in y_pred:\r\n",
        "  for j in i:\r\n",
        "    word += j \r\n",
        "  new_y_pred.append(word)\r\n",
        "  word = \"\"\r\n",
        "\r\n",
        "print (\"GaussianNBClassifier accuracy: {0:.3f}\".format(model.accuracy(y_test, new_y_pred)))\r\n",
        "\r\n",
        "# numbering each class by 0 , 1 and 2 \r\n",
        "new_y_pred = numbering(new_y_pred)\r\n",
        "\r\n",
        "# the same thing for y_test \r\n",
        "new_y_test =  numbering(y_test)\r\n",
        "\r\n",
        "classes = 3 # number of classes\r\n",
        "counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) \r\n",
        "                for i in range(len(y_test))])\r\n",
        "          for pred_class in range( classes )] \r\n",
        "          for true_class in range( classes )]\r\n",
        "    \r\n",
        "print(\"confiusion matrix : \" )\r\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNBClassifier accuracy: 0.378\n",
            "confiusion matrix : \n",
            "[[14, 0, 0], [13, 0, 0], [10, 0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTSG-TQIPI6X",
        "outputId": "e3829898-6dc1-48b8-d56b-938210c5547b"
      },
      "source": [
        "#from GaussianNBClassifier import GaussianNBClassifier\r\n",
        "from pandas import DataFrame\r\n",
        "from itertools import islice \r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "\r\n",
        "#dataset = random.sample(dataset, len(dataset))\r\n",
        "# Using islice  to declare folds\r\n",
        "Inputt = iter(random.sample(dataset, len(dataset))) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "\r\n",
        "X_train = folds[3]+folds[2]+folds[0]\r\n",
        "y_train = []\r\n",
        "new_X_train = []\r\n",
        "for x in X_train:\r\n",
        "  y_train.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_train.append(x)\r\n",
        "\r\n",
        "X_test = folds[1]\r\n",
        "y_test = []\r\n",
        "new_X_test = []\r\n",
        "for x in X_test:\r\n",
        "  y_test.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_test.append(x)\r\n",
        "\r\n",
        "model = GaussianNBClassifier()\r\n",
        "model.fit(new_X_train, y_train)\r\n",
        "y_pred = model.predict(new_X_test)\r\n",
        "word = \"\"\r\n",
        "new_y_pred = []\r\n",
        "\r\n",
        "for i in y_pred:\r\n",
        "  for j in i:\r\n",
        "    word += j \r\n",
        "  new_y_pred.append(word)\r\n",
        "  word = \"\"\r\n",
        "\r\n",
        "print (\"GaussianNBClassifier accuracy: {0:.3f}\".format(model.accuracy(y_test, new_y_pred)))\r\n",
        "\r\n",
        "# numbering each class by 0 , 1 and 2 \r\n",
        "new_y_pred = numbering(new_y_pred)\r\n",
        "\r\n",
        "# the same thing for y_test \r\n",
        "new_y_test =  numbering(y_test)\r\n",
        "\r\n",
        "classes = 3 # number of classes\r\n",
        "counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) \r\n",
        "                for i in range(len(y_test))])\r\n",
        "          for pred_class in range( classes )] \r\n",
        "          for true_class in range( classes )]\r\n",
        "    \r\n",
        "print(\"confiusion matrix : \" )\r\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNBClassifier accuracy: 0.378\n",
            "confiusion matrix : \n",
            "[[0, 0, 13], [0, 0, 10], [0, 0, 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKSMqz8NNa1N",
        "outputId": "e6be0ded-adac-451f-b2e2-30012b32d58a"
      },
      "source": [
        "#from GaussianNBClassifier import GaussianNBClassifier\r\n",
        "from pandas import DataFrame\r\n",
        "from itertools import islice \r\n",
        "\r\n",
        "filename = '/content/iris .csv'\r\n",
        "dataset = load_csv(filename)\r\n",
        "length_to_split = [37, 37, 37, 37] \r\n",
        "#dataset = random.sample(dataset, len(dataset))\r\n",
        "# Using islice to declare folds\r\n",
        "Inputt = iter(random.sample(dataset, len(dataset))) \r\n",
        "folds = [list(islice(Inputt, elem)) \r\n",
        "          for elem in length_to_split] \r\n",
        "\r\n",
        "X_train = folds[1]+folds[2]+folds[3]\r\n",
        "y_train = []\r\n",
        "new_X_train = []\r\n",
        "for x in X_train:\r\n",
        "  y_train.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_train.append(x)\r\n",
        "\r\n",
        "X_test = folds[0]\r\n",
        "y_test = []\r\n",
        "new_X_test = []\r\n",
        "for x in X_test:\r\n",
        "  y_test.append(x[4])\r\n",
        "  x.remove(x[4])\r\n",
        "  new_X_test.append(x)\r\n",
        "\r\n",
        "model = GaussianNBClassifier()\r\n",
        "model.fit(new_X_train, y_train)\r\n",
        "y_pred = model.predict(new_X_test)\r\n",
        "word = \"\"\r\n",
        "new_y_pred = []  \r\n",
        "\r\n",
        "# fixing the template of data in y_pred form tuple to list\r\n",
        "for i in y_pred:\r\n",
        "  for j in i:\r\n",
        "    word += j \r\n",
        "  new_y_pred.append(word)\r\n",
        "  word = \"\"\r\n",
        "\r\n",
        "\r\n",
        "print (\"GaussianNBClassifier accuracy: {0:.3f}\".format(model.accuracy(y_test, new_y_pred)))\r\n",
        "\r\n",
        "# numbering each class by 0 , 1 and 2 \r\n",
        "new_y_pred = numbering(new_y_pred)\r\n",
        "\r\n",
        "# the same thing for y_test \r\n",
        "new_y_test =  numbering(y_test)\r\n",
        "\r\n",
        "classes = 3 # number of classes\r\n",
        "counts = [[sum([(new_y_test[i] == true_class) and (new_y_pred[i] == pred_class) \r\n",
        "                for i in range(len(y_test))])\r\n",
        "          for pred_class in range( classes )] \r\n",
        "          for true_class in range( classes )]\r\n",
        "    \r\n",
        "print(\"confiusion matrix : \" )\r\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GaussianNBClassifier accuracy: 0.351\n",
            "confiusion matrix : \n",
            "[[0, 13, 0], [0, 13, 0], [0, 11, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbPrV7VqdCN2"
      },
      "source": [
        "=> so the average for gaussian naive bayes is :\r\n",
        "37.125 %\r\n"
      ]
    }
  ]
}